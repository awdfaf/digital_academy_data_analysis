{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b18c5781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 :  (60000, 28, 28) (60000,)\n",
      "테스트데이터 :  (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 실행시 동일한 결과를 얻기 위해 설정\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "# 패션 데이터 읽어들이기\n",
    "(train_input, train_target),(test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 데이터 형태 확인\n",
    "print(\"훈련데이터 : \", train_input.shape, train_target.shape)\n",
    "print(\"테스트데이터 : \", test_input.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667e12b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 정규화\n",
    "train_scaled = train_input / 255.0\n",
    "train_scaled = train_scaled.reshape(-1,28*28)\n",
    "train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1bc894b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784) (48000,)\n",
      "(12000, 784) (12000,)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 및 테 스트 검증 셋으로 분리\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled,train_target,\n",
    "                                                                      test_size=0.2,random_state=42)\n",
    "\n",
    "print(train_scaled.shape,train_target.shape)\n",
    "print(val_scaled.shape,val_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99dcc3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.dense.Dense object at 0x000001F9B353B310> <keras.layers.core.dense.Dense object at 0x000001F9B353B580>\n"
     ]
    }
   ],
   "source": [
    "# 인공신경망 모델에 신경망층 추가하는 방법(3가지)\n",
    "\n",
    "# 1. 층을 먼저 만들고, 신경망 모델 생성 시 추가하기\n",
    "# input_shape가 있으면 입력계층(훈련에 기여)\n",
    "dense1 = keras.layers.Dense(100, activation=\"sigmoid\", input_shape=(784, ))\n",
    "# 마지막 softmax층은 출력계층(훈련에 기여)\n",
    "dense2 = keras.layers.Dense(10, activation=\"softmax\")\n",
    "print(dense1, dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0cac502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1f9b30502e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인공신경망(심층신경망) 생성\n",
    "# 훈련모델 생성\n",
    "model = keras.Sequential([dense1,dense2])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c18a0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "792d8e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"패션 MNIST 심층신경망 모델\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2. 심층신경망 모델 생성시 → 신경망층을 함께 만들기\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"sigmoid\", input_shape=(784, ), name=\"hidden\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\", name=\"output\")\n",
    "], name=\"패션 MNIST 심층신경망 모델\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90e4e76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 3. 심층신경망 모델 생성 후 → 신경망층 추가하기(add함수)\n",
    "# 가장 많이 사용되는 방식\n",
    "\n",
    "# 모델생성\n",
    "model = keras.Sequential()\n",
    "# 신경망층 추가\n",
    "model.add(keras.layers.Dense(100, activation=\"sigmoid\", input_shape=(784, )))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# 모델 구조 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74091dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1f9cb35ddc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 설정하기 : 설정함수 compile\n",
    "# 정수값을 이용한 분류 및 정확도 확인할 수 있도록 설정\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "model\n",
    "\n",
    "# loss : 손실함수 \n",
    "# 손실함수는 실제값과 예측값의 차이를 수치화해주는 함수\n",
    "# 이 두 값의 차이, 즉 오차가 클수록 손실함수의 값은 크고 오차가 작을수록 손실함수의 값은 작아짐\n",
    "# 회귀 문제에서는 평균제곱오자(MSE)사용\n",
    "# 분류 문제에서는 xxx crossentropy사용\n",
    "# 딥러닝의 학습과정 : 손실함수의 값을 최소화하는 두 개의 매개변수인 가중치와 편향의 값을 찾는것이 목적\n",
    "# 손실함수의 개념 기억"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb2759a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 762us/step - loss: 0.5630 - accuracy: 0.8083\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 760us/step - loss: 0.4082 - accuracy: 0.8528\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 0.3744 - accuracy: 0.8654\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 742us/step - loss: 0.3504 - accuracy: 0.8729\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 0.3329 - accuracy: 0.8780\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 736us/step - loss: 0.3218 - accuracy: 0.8825\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 830us/step - loss: 0.3102 - accuracy: 0.8858\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 890us/step - loss: 0.3003 - accuracy: 0.8903\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 0.2890 - accuracy: 0.8949\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 0.2824 - accuracy: 0.8981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9cb37d430>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련시키기\n",
    "model.fit(train_scaled, train_target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5939efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 505us/step - loss: 0.3359 - accuracy: 0.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3359447121620178, 0.8813333511352539]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련모델 평가하기\n",
    "# 검증데이터로 평가\n",
    "model.evaluate(val_scaled,val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b4d789f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28) (48000,)\n",
      "(12000, 28, 28) (12000,)\n"
     ]
    }
   ],
   "source": [
    "# 전처리 계층 사용\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 패션데이터 읽어들이기\n",
    "(train_input, train_target),(test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
    "# 정규화하기\n",
    "train_scaled = train_input / 255.0\n",
    "# 차원축소 하지 않기 : 전처리 계층 사용\n",
    "# 훈련 및 검증 데이터셋으로 분류하기(8:2)\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled,train_target,\n",
    "                                                                      test_size=0.2,random_state=42)\n",
    "\n",
    "print(train_scaled.shape,train_target.shape)\n",
    "print(val_scaled.shape,val_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76e3a1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1f9b3053610>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련모델 생성\n",
    "model = keras.Sequential()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3b73ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망층 추가 : 전처리 계층 추가\n",
    "# Flatten : 차원 축소 계층(2차원을 1차원으로)\n",
    "# 훈련시 적용\n",
    "# 훈련의 성능에 기여하지 않으며, 데이터 전처리에만 사용되는 계층\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5502f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능에 기여하는 계층  : 은닉층(hidden layer) \n",
    "model.add(keras.layers.Dense(100,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "997006a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층 추가하기\n",
    "# 가장 하단의 위치하는 신경망층\n",
    "# 훈련성능에 기여\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf110b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f5064aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1f9b3053610>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련모델 설정\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64a96bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 1s 762us/step - loss: 0.2710 - accuracy: 0.9044\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 0.2649 - accuracy: 0.9067\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 1s 736us/step - loss: 0.2607 - accuracy: 0.9089\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 1s 738us/step - loss: 0.2518 - accuracy: 0.9130\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 1s 732us/step - loss: 0.2521 - accuracy: 0.9116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9c3e1fee0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련시키기\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c814ee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 484us/step - loss: 0.4191 - accuracy: 0.8823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4191235303878784, 0.8823333382606506]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련모델 평가하기\n",
    "# 검증데이터로 평가\n",
    "model .evaluate(val_scaled,val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e97bf509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 설정 방법 - 1\n",
    "# 최초에 훈련 정확도만 확인하고자 할 때\n",
    "model.compile(optimizer=\"sgd\", loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b265b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 설정 방법 - 2\n",
    "# 옵티마이저 클래스 튜닝시 사용\n",
    "sgd = keras.optimizers.SGD()\n",
    "model.compile(optimizer=sgd, loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2c4672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 튜닝\n",
    "# [learning rate(학습률)]\n",
    "# 훈련모델의 성능을 향상시키는 방법 중 한가지로 가장 loss가 적은 local minimum(경사하강 종착지)까지 \n",
    "# 걸어간다고 생각 할 때 학습률은 걸음의 보폭이라 할 수 있다\n",
    "# 학습률이 너무 크면 minimum을 지나칠 수 있다\n",
    "# 반대로 학습률이 너무 작으면 local minimum까지 도달 할 수 있어도 시간이 매우 오래 걸림\n",
    "# 기본 학습률은 0.01\n",
    "sgd = keras.optimizers.SGD(learning_rate=0.1)\n",
    "model.compile(optimizer=sgd, loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03f25e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [momentum(모멘텀)]\n",
    "# 경사하강법의 최적화 알고리즘\n",
    "# 물리학에서 쓰이는 용어로 운동향, 동력을 뜻함\n",
    "# 물리학의 개념을 훈련에 적용한 알고리즘\n",
    "# 관성과 가속도를 넣어서 이동하던 한 벙형으로 좀 더 이동할 수 있도록 하기위한 개념\n",
    "# 일반적으로 딥러닝의 경사하강법은 지그재그로 이동하면서 하강\n",
    "# 지그재그로 이동하는 방식을 관성과 가속도를 적용해서 최대한 이동하는 방향을 유지하면서 지그재그로 이동할 수 있도록 처리\n",
    "# <모멘텀의 중요 개념>\n",
    "# 현재이동하는 방향과는 별개로 과거에 이동을 했던 방향을 기억함\n",
    "# 과거의 방향으로 일정량을 추가하여 이동\n",
    "# 과거의 행동을 저장하여 사용\n",
    "# 즉, 누적된 과거 데이터를 현재 데이터에 보정하려는 방식\n",
    "# 메모리 사용량이 많다는 단점\n",
    "\n",
    "# [nesterov]\n",
    "# 모멘텀 최적화 알고리즘의 변종 알고리즘\n",
    "# 현재 위치가 아닌, 모멘텀의 방향으로 조금 앞서서 경사를 계산\n",
    "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True, learning_rate=0.1)\n",
    "model.compile(optimizer=sgd, loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0bfc4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adagrad\n",
    "adagrad = keras.optimizers.Adagrad()\n",
    "model.compile(optimizer=adagrad, loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4c2c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSprop\n",
    "rmsprop = keras.optimizers.RMSprop()\n",
    "model.compile(optimizer=rmsprop, loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8c6f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam \n",
    "adam = keras.optimizers.Adam()\n",
    "model.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a197eddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28) (48000,)\n",
      "(12000, 28, 28) (12000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1f9c637bb20>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델생성\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 패션데이터 읽어들이기\n",
    "(train_input, train_target),(test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
    "# 정규화하기\n",
    "train_scaled = train_input / 255.0\n",
    "# 차원축소 하지 않기\n",
    "# 훈련 및 검증 데이터셋으로 분류하기(8:2)\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled,train_target,\n",
    "                                                                      test_size=0.2,random_state=42)\n",
    "\n",
    "print(train_scaled.shape,train_target.shape)\n",
    "print(val_scaled.shape,val_target.shape)\n",
    "\n",
    "# 훈련모델 생성\n",
    "model = keras.Sequential()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69e3f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 계층 추가하기 : 1차원으로 만들어주는 계층\n",
    "# 신경망층 추가 : 전처리 계층 추가\n",
    "# Flatten : 차원 축소 계층(2차원을 1차원으로)\n",
    "# 훈련시 적용\n",
    "# 훈련의 성능에 기여하지 않으며, 데이터 전처리에만 사용되는 계층\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "931e8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu hidden layer 추가\n",
    "# 성능에 기여하는 계층  : 은닉층(hidden layer) \n",
    "model.add(keras.layers.Dense(100,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b5821a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층 추가\n",
    "# 가장 하단의 위치하는 신경망층\n",
    "# 훈련성능에 기여\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1936895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델생성하기 : 옵티마이저 adam사용\n",
    "# Adam \n",
    "# 가장먼저 시도하면 좋은 알고리즘\n",
    "# 방향과 학습률을 모두 적절하게 성능개선을 해주는 알고리즘\n",
    "adam = keras.optimizers.Adam()\n",
    "model.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89f32067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 0.5212 - accuracy: 0.8176\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 0.3927 - accuracy: 0.8586\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 797us/step - loss: 0.3538 - accuracy: 0.8714\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 915us/step - loss: 0.3289 - accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.3088 - accuracy: 0.8857\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 694us/step - loss: 0.2935 - accuracy: 0.8916\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 668us/step - loss: 0.2813 - accuracy: 0.8969\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 673us/step - loss: 0.2685 - accuracy: 0.8999\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 684us/step - loss: 0.2598 - accuracy: 0.9042\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 668us/step - loss: 0.2499 - accuracy: 0.9086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9c6370670>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 : 반복10회\n",
    "# 훈련시키기\n",
    "model.fit(train_scaled, train_target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0efed3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 495us/step - loss: 0.3417 - accuracy: 0.8778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3417114317417145, 0.8778333067893982]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 성능평가\n",
    "# 훈련모델 평가하기\n",
    "# 검증데이터로 평가\n",
    "model.evaluate(val_scaled,val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3df6c4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28) (48000,)\n",
      "(12000, 28, 28) (12000,)\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 687us/step - loss: 1.1696 - accuracy: 0.6522\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 681us/step - loss: 0.7826 - accuracy: 0.7555\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 851us/step - loss: 0.6985 - accuracy: 0.7776\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 0.6526 - accuracy: 0.7907\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 698us/step - loss: 0.6227 - accuracy: 0.7997\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 893us/step - loss: 0.6013 - accuracy: 0.8054\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 808us/step - loss: 0.5845 - accuracy: 0.8099\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 0.5710 - accuracy: 0.8134\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 0.5599 - accuracy: 0.8161\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 724us/step - loss: 0.5502 - accuracy: 0.8193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9c84bafa0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델생성\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 패션데이터 읽어들이기\n",
    "(train_input, train_target),(test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
    "# 정규화하기\n",
    "train_scaled = train_input / 255.0\n",
    "# 차원축소 하지 않기\n",
    "# 훈련 및 검증 데이터셋으로 분류하기(8:2)\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled,train_target,\n",
    "                                                                      test_size=0.2,random_state=42)\n",
    "\n",
    "print(train_scaled.shape,train_target.shape)\n",
    "print(val_scaled.shape,val_target.shape)\n",
    "\n",
    "# 훈련모델 생성\n",
    "model = keras.Sequential()\n",
    "\n",
    "# 전처리 계층 추가하기 : 1차원으로 만들어주는 계층\n",
    "# 신경망층 추가 : 전처리 계층 추가\n",
    "# Flatten : 차원 축소 계층(2차원을 1차원으로)\n",
    "# 훈련시 적용\n",
    "# 훈련의 성능에 기여하지 않으며, 데이터 전처리에만 사용되는 계층\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "# relu hidden layer 추가\n",
    "# 성능에 기여하는 계층  : 은닉층(hidden layer) \n",
    "model.add(keras.layers.Dense(100,activation=\"relu\"))\n",
    "\n",
    "# 출력층 추가\n",
    "# 가장 하단의 위치하는 신경망층\n",
    "# 훈련성능에 기여\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "# Adagrad\n",
    "adagrad = keras.optimizers.Adagrad()\n",
    "model.compile(optimizer=adagrad, loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "# 훈련 : 반복10회\n",
    "# 훈련시키기\n",
    "model.fit(train_scaled, train_target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f95a5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 518us/step - loss: 0.5593 - accuracy: 0.8147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5593026876449585, 0.8146666884422302]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 성능평가\n",
    "# 훈련모델 평가하기\n",
    "# 검증데이터로 평가\n",
    "model.evaluate(val_scaled,val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92cbc65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28) (48000,)\n",
      "(12000, 28, 28) (12000,)\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 883us/step - loss: 0.5313 - accuracy: 0.8111\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 0.3929 - accuracy: 0.8568\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 947us/step - loss: 0.3564 - accuracy: 0.8716\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 867us/step - loss: 0.3339 - accuracy: 0.8808\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 827us/step - loss: 0.3195 - accuracy: 0.8857\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 886us/step - loss: 0.3096 - accuracy: 0.8897\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 835us/step - loss: 0.2992 - accuracy: 0.8952\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 937us/step - loss: 0.2911 - accuracy: 0.8973\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 941us/step - loss: 0.2823 - accuracy: 0.9006\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 0.2769 - accuracy: 0.9029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9c3e74b50>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델생성\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 패션데이터 읽어들이기\n",
    "(train_input, train_target),(test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
    "# 정규화하기\n",
    "train_scaled = train_input / 255.0\n",
    "# 차원축소 하지 않기\n",
    "# 훈련 및 검증 데이터셋으로 분류하기(8:2)\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled,train_target,\n",
    "                                                                      test_size=0.2,random_state=42)\n",
    "\n",
    "print(train_scaled.shape,train_target.shape)\n",
    "print(val_scaled.shape,val_target.shape)\n",
    "\n",
    "# 훈련모델 생성\n",
    "model = keras.Sequential()\n",
    "\n",
    "# 전처리 계층 추가하기 : 1차원으로 만들어주는 계층\n",
    "# 신경망층 추가 : 전처리 계층 추가\n",
    "# Flatten : 차원 축소 계층(2차원을 1차원으로)\n",
    "# 훈련시 적용\n",
    "# 훈련의 성능에 기여하지 않으며, 데이터 전처리에만 사용되는 계층\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "# relu hidden layer 추가\n",
    "# 성능에 기여하는 계층  : 은닉층(hidden layer) \n",
    "model.add(keras.layers.Dense(100,activation=\"relu\"))\n",
    "\n",
    "# 출력층 추가\n",
    "# 가장 하단의 위치하는 신경망층\n",
    "# 훈련성능에 기여\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "# RMSprop\n",
    "rmsprop = keras.optimizers.RMSprop()\n",
    "model.compile(optimizer=rmsprop, loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "# 훈련 : 반복10회\n",
    "# 훈련시키기\n",
    "model.fit(train_scaled, train_target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa6629a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 554us/step - loss: 0.3909 - accuracy: 0.8844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39088213443756104"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 성능평가\n",
    "# 훈련모델 평가하기\n",
    "# 검증데이터로 평가\n",
    "model.evaluate(val_scaled,val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ac370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adagrad, RMSprop, Adam 중 성능평가 결과가 가장높은 옵티마이저를 선택할 수 있도록\n",
    "# 한번에 처리하도록 하기\n",
    "# Adagrad, RMSprop, Adam을 함수를 통해 최종출력결과는 가장 높은 옵티마이저 이름과 성능결과 출력\n",
    "# 함수에 전달하는 값 : 옵티마이저 이름, 반복횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "35f86053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def findOptimizer(opt, ep):\n",
    "    (train_input, train_target),(test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
    "    train_scaled = train_input / 255.0\n",
    "    train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled,train_target,\n",
    "                                                                      test_size=0.2,random_state=42)\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "    model.add(keras.layers.Dense(100,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "    findeva = []\n",
    "    num = []\n",
    "    for i in opt:\n",
    "        op = i\n",
    "        model.compile(optimizer=op, loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "        model.fit(train_scaled, train_target, epochs=10)\n",
    "        findeva.append(model.evaluate(val_scaled,val_target)[1])\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"가장 성능이 우수한 옵티마이저 : \",opt[findeva.index(max(findeva))])\n",
    "    print(\"성능결과 : \",max(findeva))\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "75ba4b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 663us/step - loss: 1.1240 - accuracy: 0.6559\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 666us/step - loss: 0.7635 - accuracy: 0.7503\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 847us/step - loss: 0.6848 - accuracy: 0.7784\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 676us/step - loss: 0.6414 - accuracy: 0.7939\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 654us/step - loss: 0.6122 - accuracy: 0.8029\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 684us/step - loss: 0.5910 - accuracy: 0.8091\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 686us/step - loss: 0.5741 - accuracy: 0.8138\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 658us/step - loss: 0.5602 - accuracy: 0.8181\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 659us/step - loss: 0.5489 - accuracy: 0.8213\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 668us/step - loss: 0.5391 - accuracy: 0.8238\n",
      "375/375 [==============================] - 0s 631us/step - loss: 0.5507 - accuracy: 0.8188\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 937us/step - loss: 0.4919 - accuracy: 0.8260\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 895us/step - loss: 0.3879 - accuracy: 0.8594\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 873us/step - loss: 0.3516 - accuracy: 0.8741\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 883us/step - loss: 0.3315 - accuracy: 0.8819\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 890us/step - loss: 0.3160 - accuracy: 0.8869\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 798us/step - loss: 0.3054 - accuracy: 0.8926\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 846us/step - loss: 0.2955 - accuracy: 0.8949\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.2900 - accuracy: 0.8974\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 736us/step - loss: 0.2786 - accuracy: 0.9024\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.2754 - accuracy: 0.9036\n",
      "375/375 [==============================] - 0s 516us/step - loss: 0.3918 - accuracy: 0.8801\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 690us/step - loss: 0.2670 - accuracy: 0.9040\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 709us/step - loss: 0.2466 - accuracy: 0.9082\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 675us/step - loss: 0.2386 - accuracy: 0.9123\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 670us/step - loss: 0.2310 - accuracy: 0.9135\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 672us/step - loss: 0.2245 - accuracy: 0.9162\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 672us/step - loss: 0.2134 - accuracy: 0.9204\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 692us/step - loss: 0.2113 - accuracy: 0.9213\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 679us/step - loss: 0.2035 - accuracy: 0.9229\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 665us/step - loss: 0.1971 - accuracy: 0.9255\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 697us/step - loss: 0.1923 - accuracy: 0.9278\n",
      "375/375 [==============================] - 0s 492us/step - loss: 0.3630 - accuracy: 0.8873\n",
      "-------------------------------\n",
      "가장 성능이 우수한 옵티마이저 :  <keras.optimizer_v2.adam.Adam object at 0x000001F9CED64820>\n",
      "성능결과 :  0.8872500061988831\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "a = keras.optimizers.Adagrad()\n",
    "b = keras.optimizers.RMSprop()\n",
    "c = keras.optimizers.Adam()\n",
    "opt = [a,b,c]\n",
    "findOptimizer(opt,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "222dfded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 1s 676us/step - loss: 1.1659 - accuracy: 0.6549\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 683us/step - loss: 0.7647 - accuracy: 0.7623\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 696us/step - loss: 0.6798 - accuracy: 0.7874\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 0.6349 - accuracy: 0.7988\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 720us/step - loss: 0.6055 - accuracy: 0.8065\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.5847 - accuracy: 0.8120\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 702us/step - loss: 0.5685 - accuracy: 0.8163\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 679us/step - loss: 0.5555 - accuracy: 0.8197\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 678us/step - loss: 0.5449 - accuracy: 0.8220\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 672us/step - loss: 0.5357 - accuracy: 0.8246\n",
      "375/375 [==============================] - 0s 525us/step - loss: 0.5451 - accuracy: 0.8199\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5271 - accuracy: 0.8132\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3917 - accuracy: 0.8574\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3567 - accuracy: 0.8715\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3328 - accuracy: 0.8808\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3167 - accuracy: 0.8866\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3056 - accuracy: 0.8919\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2970 - accuracy: 0.8935\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2903 - accuracy: 0.8969\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2820 - accuracy: 0.9003\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2765 - accuracy: 0.9035\n",
      "375/375 [==============================] - 0s 738us/step - loss: 0.3887 - accuracy: 0.8792\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 977us/step - loss: 0.5237 - accuracy: 0.8171\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 1s 973us/step - loss: 0.3935 - accuracy: 0.8600\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 1s 975us/step - loss: 0.3532 - accuracy: 0.8731\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 1s 980us/step - loss: 0.3275 - accuracy: 0.8813\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 1s 973us/step - loss: 0.3073 - accuracy: 0.8869\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 1s 968us/step - loss: 0.2909 - accuracy: 0.8935\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 1s 972us/step - loss: 0.2787 - accuracy: 0.8962\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 1s 967us/step - loss: 0.2665 - accuracy: 0.9007\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 1s 969us/step - loss: 0.2560 - accuracy: 0.9041\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 1s 977us/step - loss: 0.2449 - accuracy: 0.9089\n",
      "375/375 [==============================] - 0s 737us/step - loss: 0.3386 - accuracy: 0.8795\n",
      "best_opt= adam |  best_eval= 0.8794999718666077\n",
      "best_loss_opt= adam |best_loss= 0.33862757682800293\n"
     ]
    }
   ],
   "source": [
    "def getBestEval(opt,epoch):\n",
    "        ### 1. 모델 생성하기\n",
    "    model=keras.Sequential()\n",
    "    ### 2. 전처리 계층 추가하기 : 1차원으로 만들어주는 계층\n",
    "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "    ### 3. relu hidden layer 추가\n",
    "    model.add(keras.layers.Dense(100,activation=\"relu\"))\n",
    "    ### 4. 출력층(output layer) 추가\n",
    "    model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "    # 모델 설정\n",
    "    model.compile(optimizer=opt,\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics=\"accuracy\")\n",
    "     ### 6. 훈련시키기 : 반복 10회\n",
    "    model.fit(train_scaled,train_target,epochs=10)\n",
    "    #\n",
    "    rs_eval=model.evaluate(val_scaled,val_target)\n",
    "    \n",
    "    return rs_eval\n",
    "\n",
    "optimizers=[\"adagrad\",\"rmsprop\",\"adam\"]\n",
    "\n",
    "best_eval=0.0 # 가장 높은 정확도\n",
    "best_opt=\"\"# 가장\n",
    "\n",
    "best_loss=1.0 # 가장 낮은 손실율\n",
    "best_loss_opt=\"\" # 가장 낮은 손실율일때의 옵티마이저\n",
    "\n",
    "for opt in optimizers :\n",
    "    # 함수호출\n",
    "    rs=getBestEval(opt,2)\n",
    "    ## 가장 낮은 손실율과 이 때의 옵티마이저 처리하기\n",
    "    if best_loss > rs[0]:\n",
    "        best_loss=rs[0]\n",
    "        best_loss_opt=opt\n",
    "        \n",
    "    ## 가장 높은 정확도와 이 때의 옵티마이저 처리하기\n",
    "    if best_eval<rs[1]:\n",
    "        best_eval=rs[1]\n",
    "        best_opt=opt\n",
    "    \n",
    "print(\"best_opt=\",best_opt, \"|  best_eval=\",best_eval)\n",
    "print(\"best_loss_opt=\",best_loss_opt,\"|best_loss=\",best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b9c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 선택시 \n",
    "# 성능이 높은쪽과 손실률이 낮은쪽 중 선택은 손실률 기준(차이가 많이 안나는 경우)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a31a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e804de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40344f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f9800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36796af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d08da7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab86f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484838d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1de0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pknu_deep_kernel",
   "language": "python",
   "name": "pknu_deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
