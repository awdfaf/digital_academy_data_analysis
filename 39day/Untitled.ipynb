{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdfac8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 정의\n",
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf312d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['cls.predictions.decoder.bias', 'bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbdc7be8cc264263b69eea82d93c9302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72cc396df105406d839e45bd3622e7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcffd8c314a4444b857dbb44c63aca1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc545aabb774f1aba6b66e3e8716f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.models.bert.modeling_tf_bert.TFBertForMaskedLM object at 0x000001F4A34FDD30>\n",
      "BertTokenizerFast(name_or_path='klue/bert-base', vocab_size=32000, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "# from_pretrained(Bert모델 이름)\n",
    "# klue/bert-base : 버트 모델 이름으로 [mask] 단어를 맞추기 위한 모델링 구조로 로드\n",
    "# 함께 사용되는 라이브러리는 AutoTokenizer의 from_pretrained() 함수\n",
    "model = TFBertForMaskedLM.from_pretrained(\"klue/bert-base\",\n",
    "                                         from_pt=True)\n",
    "# from_pretrained(\"model이 설정한 Bert모델 이름과 동일\")\n",
    "# 모델이 학습 되었을 당시에 사용되었던 토큰나이저를 자동으로 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "print(model)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cea98ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "축구는 정말 재미있는 [MASK]다.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 정의\n",
    "text = \"축구는 정말 재미있는 [MASK]다.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79710a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[   2, 4713, 2259, 3944, 6001, 2259,    4,  809,   18,    3]])>, 'token_type_ids': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>}\n"
     ]
    }
   ],
   "source": [
    "# 마스크 언어 모델 입력으로 넣기\n",
    "# 결과 값은 텐서\n",
    "inputs = tokenizer(text, return_tensors=\"tf\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de4829ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[   2 4713 2259 3944 6001 2259    4  809   18    3]], shape=(1, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "### 정수 인코딩 결과 확인하기\n",
    "print(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f7802c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0 0 0 0 0 0 0 0 0 0]], shape=(1, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "### 문장 단위를 세그먼트라는 용어를 사용\n",
    "# - 문장이 1개 있으면 세그먼트 0\n",
    "# - 세그먼트 확인하기\n",
    "print(inputs[\"token_type_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baedfb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0369efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.pipelines.fill_mask.FillMaskPipeline object at 0x000001F4A34DC430>\n"
     ]
    }
   ],
   "source": [
    "from transformers import FillMaskPipeline\n",
    "\n",
    "# 모델 훈련시키기\n",
    "# 훈련된 모델 연결\n",
    "# model과 tokenizer 연결\n",
    "# 연결은 FillMaskPipline 라이브러리에 의해 연결\n",
    "pip = FillMaskPipeline(model=model, tokenizer=tokenizer)\n",
    "print(pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "877e16cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8963512182235718,\n",
       "  'token': 4559,\n",
       "  'token_str': '스포츠',\n",
       "  'sequence': '축구는 정말 재미있는 스포츠 다.'},\n",
       " {'score': 0.025957640260457993,\n",
       "  'token': 568,\n",
       "  'token_str': '거',\n",
       "  'sequence': '축구는 정말 재미있는 거 다.'},\n",
       " {'score': 0.010033938102424145,\n",
       "  'token': 3682,\n",
       "  'token_str': '경기',\n",
       "  'sequence': '축구는 정말 재미있는 경기 다.'},\n",
       " {'score': 0.007924390956759453,\n",
       "  'token': 4713,\n",
       "  'token_str': '축구',\n",
       "  'sequence': '축구는 정말 재미있는 축구 다.'},\n",
       " {'score': 0.007844238542020321,\n",
       "  'token': 5845,\n",
       "  'token_str': '놀이',\n",
       "  'sequence': '축구는 정말 재미있는 놀이 다.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MASK 예측 \n",
    "pip(\"축구는 정말 재미있는 [MASK]다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04da2994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.13137081265449524,\n",
       "   'token': 1330,\n",
       "   'token_str': '싫',\n",
       "   'sequence': '[CLS] 나는 공부가 싫 다. 그래도 해야 [MASK] 다. [SEP]'},\n",
       "  {'score': 0.08335502445697784,\n",
       "   'token': 1415,\n",
       "   'token_str': '없',\n",
       "   'sequence': '[CLS] 나는 공부가 없 다. 그래도 해야 [MASK] 다. [SEP]'},\n",
       "  {'score': 0.08089631795883179,\n",
       "   'token': 4390,\n",
       "   'token_str': '힘들',\n",
       "   'sequence': '[CLS] 나는 공부가 힘들 다. 그래도 해야 [MASK] 다. [SEP]'},\n",
       "  {'score': 0.0550154447555542,\n",
       "   'token': 1560,\n",
       "   'token_str': '좋',\n",
       "   'sequence': '[CLS] 나는 공부가 좋 다. 그래도 해야 [MASK] 다. [SEP]'},\n",
       "  {'score': 0.05151516571640968,\n",
       "   'token': 4258,\n",
       "   'token_str': '어렵',\n",
       "   'sequence': '[CLS] 나는 공부가 어렵 다. 그래도 해야 [MASK] 다. [SEP]'}],\n",
       " [{'score': 0.11688510328531265,\n",
       "   'token': 582,\n",
       "   'token_str': '겠',\n",
       "   'sequence': '[CLS] 나는 공부가 [MASK] 다. 그래도 해야 겠 다. [SEP]'},\n",
       "  {'score': 0.1035318523645401,\n",
       "   'token': 1902,\n",
       "   'token_str': '했',\n",
       "   'sequence': '[CLS] 나는 공부가 [MASK] 다. 그래도 해야 했 다. [SEP]'},\n",
       "  {'score': 0.09695763885974884,\n",
       "   'token': 1891,\n",
       "   'token_str': '한',\n",
       "   'sequence': '[CLS] 나는 공부가 [MASK] 다. 그래도 해야 한 다. [SEP]'},\n",
       "  {'score': 0.06771833449602127,\n",
       "   'token': 1545,\n",
       "   'token_str': '제',\n",
       "   'sequence': '[CLS] 나는 공부가 [MASK] 다. 그래도 해야 제 다. [SEP]'},\n",
       "  {'score': 0.058398064225912094,\n",
       "   'token': 860,\n",
       "   'token_str': '된',\n",
       "   'sequence': '[CLS] 나는 공부가 [MASK] 다. 그래도 해야 된 다. [SEP]'}]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip(\"나는 공부가 [MASK]다. 그래도 해야 [MASK]다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2320fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8382407426834106,\n",
       "  'token': 3771,\n",
       "  'token_str': '영화',\n",
       "  'sequence': '어벤져스는 정말 재미있는 영화 다.'},\n",
       " {'score': 0.02827559970319271,\n",
       "  'token': 568,\n",
       "  'token_str': '거',\n",
       "  'sequence': '어벤져스는 정말 재미있는 거 다.'},\n",
       " {'score': 0.017189383506774902,\n",
       "  'token': 4665,\n",
       "  'token_str': '드라마',\n",
       "  'sequence': '어벤져스는 정말 재미있는 드라마 다.'},\n",
       " {'score': 0.014989701099693775,\n",
       "  'token': 3758,\n",
       "  'token_str': '이야기',\n",
       "  'sequence': '어벤져스는 정말 재미있는 이야기 다.'},\n",
       " {'score': 0.009382650256156921,\n",
       "  'token': 4938,\n",
       "  'token_str': '장소',\n",
       "  'sequence': '어벤져스는 정말 재미있는 장소 다.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip(\"어벤져스는 정말 재미있는 [MASK]다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ea999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34183cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c96c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b872c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7dda6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca770cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pknu_nltk_kernel",
   "language": "python",
   "name": "pknu_nltk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
