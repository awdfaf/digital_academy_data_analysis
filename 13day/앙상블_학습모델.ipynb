{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- 앙상블 모델들은 결정트리(DT)를 기반으로 만들어진 모델들임\n",
    "- 앙상블 학습모델(분류 및 회귀 모두 사용가능)\n",
    "  : 랜덤포레스트(RandomForest : RT)\n",
    "  : 엑스트라 트리(Extra Trees : ET)\n",
    "  : 그레디언트 부스팅(Gradient Boosting : GD)\n",
    "  : 히스토그램 기반 그레이언트 부스팅(Histogram-base Gradient Boosting : HGB) *\n",
    "- 앙상블 학습모델(분류로만 사용 가능한 모델)\n",
    "  : XGBooting(XGB)\n",
    "  : LightGBM(LGBM) *\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee663cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n- 앙상블 학습 모델의 가장 대표격 모델\\n- 안정적인 성능으로 널리 사용되고 있음\\n- 과대적합되는 것을 막아줌 ***\\n- 검증 및 테스트데이터에서 안정적 성능을 얻을 수 있음\\n\\n<\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "<랜덤포레스트>\n",
    "- 앙상블 학습 모델의 가장 대표격 모델\n",
    "- 안정적인 성능으로 널리 사용되고 있음\n",
    "- 과대적합되는 것을 막아줌 ***\n",
    "- 검증 및 테스트데이터에서 안정적 성능을 얻을 수 있음\n",
    "\n",
    "<처리 순서>\n",
    "- 결정트리를 랜덤하게 만들어 숲을 만듦\n",
    "- 훈련데이터에서 랜덤하게 샘플 추출\n",
    "- 사용된 샘플은 다시 훈련데이터에 넣어서 랜덤하게 샘플 훈련 데이터 생성\n",
    "- 추출한 샘플 훈련데이터는 일부 중복된 값들로 추출될 수 있음\n",
    "\n",
    "<부트스트랩 샘플링(Bootstrap Sample)>\n",
    "- 데이터 원본에서 중복을 허용하여 데이터를 샘플링하는 방식\n",
    "- 원본에서 랜덤하게 샘플을 추출\n",
    "- 사용이 끝난 샘플을 원본에 다시 반환\n",
    "- 위의 순서를 반복해 다시 샘플 추출\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d28767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc04b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5197, 3) (5197,)\n",
      "(1300, 3) (1300,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "wine = pd.read_csv(\"./data/08_wine.csv\")\n",
    "\n",
    "# 훈련데이터(input, target) 생성\n",
    "wine_input = wine[[\"alcohol\",\"sugar\",\"pH\"]].to_numpy() # 2차원\n",
    "wine_target = wine[\"class\"].to_numpy() # 1차원\n",
    "\n",
    "# 훈련데이터와 테스트데이터로 분리\n",
    "train_input, test_input, train_target, test_target = train_test_split(wine_input,wine_target,\n",
    "                                                                      test_size=0.2,random_state=42)\n",
    "print(train_input.shape,train_target.shape)\n",
    "print(test_input.shape,test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90d5f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.15399957, 0.15700006, 0.15499973, 0.16399956, 0.15499997]), 'score_time': array([0.02399993, 0.02399993, 0.02399993, 0.02400017, 0.02499986]), 'test_score': array([0.88461538, 0.88942308, 0.90279115, 0.88931665, 0.88642926]), 'train_score': array([0.9971133 , 0.99663219, 0.9978355 , 0.9973545 , 0.9978355 ])}\n",
      "0.9973541965122431\n",
      "0.8905151032797809\n"
     ]
    }
   ],
   "source": [
    "# 교차검증을 통해 랜덤포레스트 모델 사용\n",
    "# 모델생성\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "# 교차검증\n",
    "# return_train_score : 훈련 및 검증결과 보여주기\n",
    "scores = cross_validate(rf, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "575bd14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973541965122431 0.8905151032797809\n"
     ]
    }
   ],
   "source": [
    "# 최종 훈련평가 결과 및 검증결과\n",
    "train_mean = np.mean(scores[\"train_score\"])\n",
    "test_mean = np.mean(scores[\"test_score\"])\n",
    "print(train_mean, test_mean)\n",
    "\n",
    "# 과대적합 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b3f1338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23167441 0.50039841 0.26792718]\n"
     ]
    }
   ],
   "source": [
    "# 튜닝\n",
    "# 특성중요도 확인\n",
    "# 랜덤포레스트 자체 훈련시키기\n",
    "rf.fit(train_input,train_target)\n",
    "print(rf.feature_importances_)\n",
    "# 특성의 순서 : 알콜, 당도, 농도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e37f2459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8934000384837406\n",
      "0.996921300750433\n",
      "0.8892307692307693\n"
     ]
    }
   ],
   "source": [
    "# 랜덤포레스트만의 특징\n",
    "# 모델생성\n",
    "# oob_score(Out of Bag) 샘플링\n",
    "#    : 교차검증 중 훈련에 참여하지 못한 샘플이 발생할 수 있는데 \n",
    "#      이러한 샘플을 훈련에 참여시킴으로써 훈련의 정확도 올림\n",
    "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
    "# 훈련시키기\n",
    "rf.fit(train_input,train_target)\n",
    "print(rf.oob_score_)\n",
    "print(rf.score(train_input,train_target))\n",
    "print(rf.score(test_input,test_target))\n",
    "# 해석\n",
    "# - oob가 사용된 score 비교시 oob 검증결과(oob_score_)와 테스트 검증결과를 비교\n",
    "# - 0.89 vs 0.88로 성능은 높지 않지만, 과대적합은 해소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb807a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- 랜덤포레스트와 유사\n",
    "- 기본적으로 100개의 결정트리를 훈련\n",
    "- 랜덤포레스트와의 차이점\n",
    "  : 부트스트랩을 지원하지 않음\n",
    "  : 훈련데이터 전체를 이용\n",
    "  : 무작위로 트리 분할\n",
    "- 특성이 많지 않은 경우 랜덤포레스트와 큰 차이 없음\n",
    "- 랜덤하게 트리를 분할하기 때문에(알아서) 계산 속도 빠름\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c23191c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9974503966084433 0.8887848893166506\n"
     ]
    }
   ],
   "source": [
    "# 모델생성\n",
    "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
    "# 교차검증\n",
    "scores = cross_validate(et, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증결과\n",
    "train_mean = np.mean(scores[\"train_score\"])\n",
    "test_mean = np.mean(scores[\"test_score\"])\n",
    "print(train_mean, test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c15ee7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그래디언트 부스팅(Gradient Boosting)\n",
    "\"\"\"\n",
    "- 깊이(max_depth)가 얕은 결정트리 사용\n",
    "  : 기본적으로 max_depth는 3\n",
    "  : 결정트리는 100개 사용\n",
    "- 기존에 다른 훈련모델의 결과가 좋지 않은 경우 사용해 볼 수 있음\n",
    "- 기존 훈련모델의 오차를 보완하여 성능을 향상하고자 할 때 사용하면 좋음\n",
    "- 랜덤포레스트보다 과대적합에 강하며, 일반화에 강함\n",
    "\n",
    "<단점>\n",
    "- 순서대로 트리를 추가(랜덤하지 않음)하기 때문에 랜덤포레스트보다 훈련속도 느림\n",
    "- 느린 속도를 개선한 모델이 '히스토그램 기반 그래디언트 부스팅 모델'임\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aac391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8881086892152563 0.8720430147331015\n"
     ]
    }
   ],
   "source": [
    "# 모델생성\n",
    "gd = GradientBoostingClassifier(random_state=42)\n",
    "# 교차검증\n",
    "scores = cross_validate(gd, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증결과\n",
    "train_mean = np.mean(scores[\"train_score\"])\n",
    "test_mean = np.mean(scores[\"test_score\"])\n",
    "print(train_mean, test_mean)\n",
    "\n",
    "# 과대적합 해소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26c84c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9464595437171814 0.8780082549788999\n"
     ]
    }
   ],
   "source": [
    "# 모델생성\n",
    "# 하이퍼 파라미터 추가\n",
    "# n_estimators : 결정트리 개수\n",
    "# learning_rate : 학습률(기본값 : 0.1, 성능향상시 값을 높이면서 확인)\n",
    "gd = GradientBoostingClassifier(n_estimators=500,\n",
    "                                learning_rate=0.2,\n",
    "                                random_state=42)\n",
    "# 교차검증\n",
    "scores = cross_validate(gd, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증결과\n",
    "train_mean = np.mean(scores[\"train_score\"])\n",
    "test_mean = np.mean(scores[\"test_score\"])\n",
    "print(train_mean, test_mean)\n",
    "\n",
    "# 과대적합 발생 -> 하이퍼파라미터 안쓰는게 낫다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- 그래디언트 부스팅의 느린속도를 개선한 모델\n",
    "- 인기가 상승하는 모델임\n",
    "- 속도 빠른 이유\n",
    "  : 최초 특성을 256개의 구간으로 나누고 시작\n",
    "  : 트리를 분할 할 때 매우 빠르게 찾을 수 있음\n",
    "- 장점\n",
    "  : 하이퍼파라미터의 기본값 만으로 안정적 성능을 얻을 수 있음\n",
    "- 성능개선은 max_iter(훈련반복횟수)를 통해 테스트 진행가능\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "522d21ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9321723946453317 0.8801241948619236\n"
     ]
    }
   ],
   "source": [
    "# 모델생성\n",
    "hgb = HistGradientBoostingClassifier(random_state=42,)\n",
    "# 교차검증\n",
    "scores = cross_validate(hgb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증결과\n",
    "train_mean = np.mean(scores[\"train_score\"])\n",
    "test_mean = np.mean(scores[\"test_score\"])\n",
    "print(train_mean, test_mean)\n",
    "\n",
    "# 과대적합 해소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "136f0570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555033709953124 0.8799326275264677\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "# 모델생성\n",
    "# tree_method : 사이킷런에서와 유사한 히스토그램 기반 그래디언트부스팅 사용 옵션\n",
    "xgb = XGBClassifier(tree_method=\"hist\",random_state=42)\n",
    "# 교차검증\n",
    "scores = cross_validate(xgb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증결과\n",
    "train_mean = np.mean(scores[\"train_score\"])\n",
    "test_mean = np.mean(scores[\"test_score\"])\n",
    "print(train_mean, test_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22541b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- 마이크로소프트에서 만든 히스토그램 기반 그래디언트 부스트 패키지\n",
    "- 훈련 속도 빠름\n",
    "- 좋은건 다 적용했다 보면 됨\n",
    "- 인기가 늘어나는 모델\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d069bc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935828414851749 0.8801251203079884\n"
     ]
    }
   ],
   "source": [
    "# 모델생성\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "# 교차검증\n",
    "scores = cross_validate(lgbm, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증결과\n",
    "train_mean = np.mean(scores[\"train_score\"])\n",
    "test_mean = np.mean(scores[\"test_score\"])\n",
    "print(train_mean, test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55ce29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5ea03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ef3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134d272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pknu_base_kernel",
   "language": "python",
   "name": "pknu_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
